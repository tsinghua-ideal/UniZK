{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c490d4",
   "metadata": {},
   "source": [
    "# Vanilla CNN layers implementation with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b9914-cce9-4d71-b20d-96df96f6403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3349aa-434a-4c9b-a451-feeb341aaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input, f):\n",
    "    \"\"\"\n",
    "    Evaluate the output of a convolutional layer using the filter f.\n",
    "    input.shape = (h, w, c)\n",
    "    f.shape = (c_out, hf, wf, c_in)\n",
    "    \"\"\"\n",
    "    h, w, c = input.shape\n",
    "    c_out, hf, wf, c_in = f.shape\n",
    "\n",
    "    assert c == c_in, \"Input channels must match!\"\n",
    "    assert hf%2 == 1, \"Height of the filter (f.shape[1]) must be an uneven number!\"\n",
    "    assert wf%2 == 1, \"Width of the filter (f.shape[2]) must be an uneven number!\"\n",
    "\n",
    "    # unilateral width and heght\n",
    "    dh = hf//2\n",
    "    dw = wf//2\n",
    "\n",
    "    # after convolution dw and dh get substracted from all sides of the image, c_out is number of convolutions which dictates # of channels\n",
    "    # initialize matrix with 0s\n",
    "    output = np.zeros(shape=(h-2*dh, w-2*dw, c_out))\n",
    "\n",
    "# run convolution\n",
    "# go over image height - kernel padding (2*dh)\n",
    "    for i in range(dh, h-dh):\n",
    "        # go over image width - kernel padding (2*dw)\n",
    "        for j in range(dw, w-dw):\n",
    "            # kernel slice\n",
    "            a = input[i-dh:i+dh+1, j-dw:j+dw+1]\n",
    "            for k in range(c_out):\n",
    "                # filter channel 1..c_out\n",
    "                b = f[k,:,:,:]\n",
    "                # apply filter\n",
    "                output[i-dh, j-dw, k] = (a*b).sum() # a.size multiplication\n",
    "    \n",
    "    n_params = f.size\n",
    "    n_multiplications = a.size * c_out * (w-2*dw) * (h-2*dh)\n",
    "    name = f\"conv {'x'.join([str(e) for e in f.shape])}\"\n",
    "    \n",
    "    return output, n_params, n_multiplications, name\n",
    "\n",
    "\n",
    "def relu_layer(input):    \n",
    "    output = input.copy()\n",
    "    output[output<0] = 0\n",
    "    \n",
    "    n_params = 0\n",
    "    n_multiplications = input.size\n",
    "    \n",
    "    return output, n_params, n_multiplications, \"relu\"\n",
    "\n",
    "\n",
    "def max_pooling_layer(input, s):\n",
    "    \"\"\"\n",
    "    Apply max pooling layer using a sxs patch.\n",
    "    \"\"\"\n",
    "    h, w, c = input.shape\n",
    "\n",
    "    assert h%s == 0, \"Height must be divisible by s!\"\n",
    "    assert w%s == 0, \"Width must be dibisible by s!\"\n",
    "\n",
    "    output = np.zeros(shape=(h//s, w//s, c))\n",
    "\n",
    "    for i in range(0, h, s):\n",
    "        for j in range(0, w, s):\n",
    "            for k in range(c):\n",
    "                a = input[i:i+s, j:j+s, k]\n",
    "                output[i//s, j//s, k] = a.max()\n",
    "    \n",
    "    n_params = 0\n",
    "    n_multiplications = input.size\n",
    "    return output, n_params, n_multiplications, \"max-pool\"\n",
    "\n",
    "\n",
    "def flatten_layer(input):\n",
    "    output = input.flatten()\n",
    "    n_params = 0\n",
    "    n_multiplications = 0\n",
    "    return output, n_params, n_multiplications, \"flatten\"\n",
    "\n",
    "\n",
    "def fully_connected_layer(input, weights, biases):\n",
    "    \"\"\"\n",
    "    Evaluate the output of a fully connected layer.\n",
    "    input.shape = (output_dim)\n",
    "    weights.shape = (output_dim, input_dim)\n",
    "    f.shape = (output_dim)\n",
    "    \"\"\"\n",
    "    assert input.ndim == 1, \"Input must be a flattend array!\"\n",
    "    assert weights.shape[1] == input.shape[0], \"Input shapes must match!\"\n",
    "    assert weights.shape[0] == biases.shape[0], \"Output shapes must match!\"\n",
    "\n",
    "    output = np.dot(weights, input) + biases\n",
    "    \n",
    "    n_params = weights.size + biases.size\n",
    "    n_multiplications = weights.size\n",
    "    name = f\"full {'x'.join([str(e) for e in weights.shape])}\"\n",
    "    \n",
    "    return output, n_params, n_multiplications, name\n",
    "\n",
    "\n",
    "def normalize(input):\n",
    "    output = input / np.linalg.norm(input)\n",
    "    n_params = 0\n",
    "    n_multiplications = 1 + input.size\n",
    "    return output, n_params, n_multiplications, \"normalize\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896d5ed",
   "metadata": {},
   "source": [
    "# Vanilla CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "p = \"{:>20} | {:>15} | {:>15} | {:>15} \"\n",
    "print(p.format(\"layer\", \"output shape\", \"#parameters\", \"#ops\"))\n",
    "print(p.format(\"-\"*20, \"-\"*15, \"-\"*15, \"-\"*15))\n",
    "\n",
    "# input\n",
    "x = np.random.randint(low=-5, high=5, size=(120,80,3))\n",
    "\n",
    "# conv layer\n",
    "f = np.random.randint(low=-10, high=+10, size=(32,5,5,3)) \n",
    "x, n_params, n_multiplications, name = conv_layer(x, f)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# max pooling\n",
    "x, n_params, n_multiplications, name =  max_pooling_layer(x, 2)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# relu layer\n",
    "x, n_params, n_multiplications, name = relu_layer(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# conv layer\n",
    "f = np.random.randint(low=-10, high=+10, size=(32,5,5,32)) \n",
    "x, n_params, n_multiplications, name = conv_layer(x, f)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# max pooling\n",
    "x, n_params, n_multiplications, name =  max_pooling_layer(x, 2)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# relu layer\n",
    "x, n_params, n_multiplications, name = relu_layer(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# flatten\n",
    "x, n_params, n_multiplications, name =  flatten_layer(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# fully connected\n",
    "weights = np.random.randint(low=-10, high=+10, size=(1000, x.shape[0])) \n",
    "biases = np.random.randint(low=-10, high=+10, size=(1000)) \n",
    "x, n_params, n_multiplications, name = fully_connected_layer(x, weights, biases)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# relu layer\n",
    "x, n_params, n_multiplications, name = relu_layer(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# fully connected\n",
    "weights = np.random.randint(low=-10, high=+10, size=(5, x.shape[0])) \n",
    "biases = np.random.randint(low=-10, high=+10, size=(5)) \n",
    "x, n_params, n_multiplications, name = fully_connected_layer(x, weights, biases)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "assert(np.isclose(x, [ -9404869, -11033050, -34374361, -20396580,  70483360.]).all())\n",
    "\n",
    "# normalization\n",
    "x, n_params, n_multiplications, name = normalize(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "print(\"\\nfinal output:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c065d3-e68b-4a63-9e7e-237dbf704819",
   "metadata": {},
   "source": [
    "# JSON example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c695a-f706-401f-b85c-b46396a8c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Encoder\n",
    "from json import JSONEncoder\n",
    "\n",
    "class Encoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "shape = (3,3,3)\n",
    "x = np.random.randint(low=-5, high=5, size=shape)\n",
    "\n",
    "x = x.flatten()\n",
    "\n",
    "# Serialization\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    \"dim\": shape,\n",
    "    \"data\": x\n",
    "    }\n",
    "\n",
    "json_data = json.dumps(data, cls=Encoder)\n",
    "\n",
    "with open(\"../src/json/test.json\", \"w\") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4e31a",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619bbbb-fad3-46ae-83b4-b74398cb953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "8388608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1787ed-b448-40e2-96e7-7d597a4660e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "4897963 / 8388608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33087999-ac7f-4ebd-b290-8dbbe3d0c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(262144)/np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae322e92-7fcb-4270-9025-392773fc6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "4896000 * 3 / (14688 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078557e-adc4-4385-be93-567aa7d93e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(14688 * 800 / 3) / np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316d646-b622-47b1-a58c-2ceb5de41c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "14688 * 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe8302-5958-427f-9453-7e2c4ff2cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "14688 * 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70387136-104a-4a18-9f20-72847ecee8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "234076 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93298188-6ed4-4e9e-b3cc-20f9778e38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = [-6276474000, 8343393300, 8266027500, -7525360600, 7814137000]\n",
    "norm = np.linalg.norm(output)\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b09558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(6276474000**2 + 8343393300**2 + 8266027500**2 + 7525360600**2 + 7814137000**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c85ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output/norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
